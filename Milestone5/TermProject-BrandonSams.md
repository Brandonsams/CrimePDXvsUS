# Term Project

## Brandon Sams

When I chose my topic for this project, I tried to choose something that:

1. Could be found from a variety of source types
2. Had plenty of numerical data associated with it

For that reason, I decided to just find a bunch of crime-related data and do some cleaning and analysis of that data. I think it worked out relatively well. My skills increased, and now there is not a daunting amount of work ahead of me the next time I want to scrape data from a website or API, for instance. I had used APIs before, but never had scraped any data from a website previously, so I had to start from square one by figuring out the basics of html. That was one of the biggest hurdles with this project.

So getting the data was a big challenge, but once I got my hands on it, it was another challenge figuring what exactly to do with it. I ended up doing some indexing and column renaming to clean some of the dataframes up. I also made sure to convert my data to the proper type before I tried to do something with it. This took some work, but I am finally getting the hang of working with data in dataframes, and that nice. Kinda proud of myself here. 

I like the database content that we dug into during the final week of this course. This showed me that there is an excellent way to save the dataframes, which is to put into a database. I especially like this, because the data can be stored at an offsite location in a secure manner. And I can come back to the data at any time, without having to run the jupyter notebook again.

But with the visualization stage, I found myself running into (what felt like) plenty of trouble when it came to visualizing something from multiple tables. I wasn't sure how to compare the data that I had collected for crime in Portland, OR to the national crime statistics that I had compiled. I get that there is probably a way to summarize the data from the Portland data set (which is much bigger), but I had no idea what would be a good way to do that. So I ended up visualizing other aspects of the data that I had cleaned.